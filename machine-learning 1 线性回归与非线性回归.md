---
title: machine-learning-1-çº¿æ€§å›å½’ä¸éçº¿æ€§å›å½’
date: 2020-03-06 11:59:20
tags: [machine learning]
categories: "machine learning"
---

# machine-learning-1-çº¿æ€§å›å½’ä¸éçº¿æ€§å›å½’

## åŸºäºæ¢¯åº¦ä¸‹é™æ³•çš„ä¸€å…ƒçº¿æ€§å›å½’åº”ç”¨

### å›å½’Regression

#### ä¸€å…ƒçº¿æ€§å›å½’

- å›å½’åˆ†æ(regression analysis)ç”¨æ¥å»ºç«‹æ–¹ç¨‹æ¨¡æ‹Ÿä¸¤ä¸ªæˆ–è€…å¤šä¸ªå˜é‡ä¹‹é—´å¦‚ä½•å…³è”
- è¢«é¢„æµ‹çš„å˜é‡å«åšï¼šå› å˜é‡(dependent variable), è¾“å‡º(output)
- è¢«ç”¨æ¥è¿›è¡Œé¢„æµ‹çš„å˜é‡å«åšï¼š è‡ªå˜é‡(independent variable), è¾“å…¥(input)
- ä¸€å…ƒçº¿æ€§å›å½’åŒ…å«ä¸€ä¸ªè‡ªå˜é‡å’Œä¸€ä¸ªå› å˜é‡
- ä»¥ä¸Šä¸¤ä¸ªå˜é‡çš„å…³ç³»ç”¨ä¸€æ¡ç›´çº¿æ¥æ¨¡æ‹Ÿ
- å¦‚æœåŒ…å«ä¸¤ä¸ªä»¥ä¸Šçš„è‡ªå˜é‡ï¼Œåˆ™ç§°ä½œå¤šå…ƒå›å½’åˆ†æ(multiple regression)

â„ğœƒ ğ‘¥ = ğœƒ0 + ğœƒ1ğ‘¥

è¿™ä¸ªæ–¹ç¨‹å¯¹åº”çš„å›¾åƒæ˜¯ä¸€æ¡ç›´çº¿ï¼Œç§°ä½œå›å½’çº¿ã€‚å…¶ä¸­ï¼Œğœƒ1ä¸ºå›å½’çº¿çš„æ–œç‡ï¼Œ ğœƒ0ä¸ºå›å½’çº¿çš„æˆªè·ã€‚

- çº¿æ€§å›å½’çš„ä¸‰ç§å…³ç³»:
  1. æ­£ç›¸å…³
  2. è´Ÿç›¸å…³
  3. ä¸ç›¸å…³

#### æ±‚è§£æ–¹ç¨‹ç³»æ•°

![](http://img.zhengyua.cn/img/20200303111133.png)

![](http://img.zhengyua.cn/img/20200303111247.png)



### ä»£ä»·å‡½æ•°Cost Function

- æœ€å°äºŒä¹˜æ³•

- çœŸå®å€¼yï¼Œé¢„æµ‹å€¼â„ğœƒ ğ‘¥ ï¼Œåˆ™è¯¯å·®å¹³æ–¹ä¸º(y âˆ’ â„_ğœƒ(x))^2

- æ‰¾åˆ°åˆé€‚çš„å‚æ•°ï¼Œä½¿å¾—è¯¯å·®å¹³æ–¹å’Œï¼š

  ![](http://img.zhengyua.cn/img/20200303111453.png)

- ![](http://img.zhengyua.cn/img/20200303111529.png)

  - ![](http://img.zhengyua.cn/img/20200303111542.png)

  - ![](http://img.zhengyua.cn/img/20200303111631.png)
  - ![](http://img.zhengyua.cn/img/20200303111704.png)
  - ![](http://img.zhengyua.cn/img/20200303111753.png)

  - ![](http://img.zhengyua.cn/img/20200303111812.png)
  - ![](http://img.zhengyua.cn/img/20200303111828.png)

#### ç›¸å…³ç³»æ•°

ä½¿ç”¨ç›¸å…³ç³»æ•°å»è¡¡é‡çº¿æ€§ç›¸å…³æ€§çš„å¼ºå¼±

![](http://img.zhengyua.cn/img/20200303111914.png)

#### å†³å®šç³»æ•°

ç›¸å…³ç³»æ•°ğ‘…2(coefficient of determination)æ˜¯ç”¨æ¥æè¿°ä¸¤ä¸ªå˜é‡ä¹‹é—´çš„çº¿æ€§å…³ç³»çš„ï¼Œä½†å†³å®šç³»æ•°çš„é€‚ç”¨èŒƒå›´æ›´å¹¿ï¼Œå¯ä»¥ç”¨äºæè¿°éçº¿æ€§æˆ–è€…æœ‰ä¸¤ä¸ªåŠä¸¤ä¸ªä»¥ä¸Šè‡ªå˜é‡çš„ç›¸å…³å…³ç³»ã€‚å®ƒå¯ä»¥ç”¨æ¥è¯„ä»·æ¨¡å‹çš„æ•ˆæœ

![](http://img.zhengyua.cn/img/20200303112016.png)

### æ¢¯åº¦ä¸‹é™æ³•Gradient Descent

![](http://img.zhengyua.cn/img/20200303112058.png)

![](http://img.zhengyua.cn/img/20200303112113.png)

- ![](http://img.zhengyua.cn/img/20200303112150.png)

  > å­¦ä¹ ç‡ä¸èƒ½å¤ªå°ï¼Œä¹Ÿä¸èƒ½å¤ªå¤§ï¼Œå¯ä»¥å¤šå°è¯•ä¸€äº›å€¼0.1,0.03,0.01,0.003,0.001,0.0003,0.0001â€¦,å¦åˆ™æœ‰å¯èƒ½ä¼šé™·å…¥å±€éƒ¨æå°å€¼

  - ![](http://img.zhengyua.cn/img/20200303112307.png)

#### ç”¨æ¢¯åº¦ä¸‹é™æ³•æ¥æ±‚è§£çº¿æ€§å›å½’

![](http://img.zhengyua.cn/img/20200303112406.png)

![](http://img.zhengyua.cn/img/20200303112547.png)

#### éå‡¸å‡½æ•°å’Œå‡¸å‡½æ•°

![](http://img.zhengyua.cn/img/20200303112654.png)

- çº¿æ€§å›å½’çš„ä»£ä»·å‡½æ•°æ˜¯å‡¸å‡½æ•°

  ![](http://img.zhengyua.cn/img/20200303112617.png)

#### ä¼˜åŒ–è¿‡ç¨‹

![](http://img.zhengyua.cn/img/20200303112729.png)

#### ä»£ç å®ç°

```python
import numpy as np
import matplotlib.pyplot as plt
#è½½å…¥æ•°æ®
data = np.genfromtxt("data.csv",delimiter=",")
x_data = data[:,0]
y_data = data[:,1]
plt.scatter(x_data,y_data)
plt.show()
#learning rate
lr = 0.0001
#æˆªè·
b = 0
#æ–œç‡
k = 0
#æœ€å¤§è¿­ä»£æ¬¡æ•°
epochs = 50

#æœ€å°äºŒä¹˜æ³•
def compute_error(b, k, x_data, y_data):
    totalError = 0
    for i in range(0,len(x_data)):
        #(çœŸå®å€¼-é¢„æµ‹å€¼)^2
        totalError += (y_data[i]-(k * x_data[i] + b)) ** 2
    return totalError / float(len(x_data)) / 2

def gradient_descent_runner(x_data, y_data, b, k, lr, epochs):
    #è®¡ç®—æ€»æ•°æ®é‡
    m = float(len(x_data))
    for i in range (epochs):
        b_grad = 0
        k_grad = 0
        for j in range (0, len(x_data)):
            b_grad += - (1/m) * (y_data[j] - ((k * x_data[j]) + b))
            k_grad += - (1/m) * x_data[j] * (y_data[j] - ((k * x_data[j]) + b))
        b = b - (lr * b_grad)
        k = k - (lr * k_grad)
        #æ¯è¿­ä»£äº”æ¬¡,è¾“å‡ºå›¾åƒ
        if i % 5 == 0:
            print("epochs :",i)
            plt.plot(x_data, y_data, 'b.')
            plt.plot(x_data, k*x_data + b, 'r')
            plt.show()
        
    return b, k


print("Starting b = {0}, k = {1}, error = {2}".format(b, k, compute_error(b, k, x_data, y_data)))
print("Running ...")
b, k = gradient_descent_runner(x_data, y_data, b, k, lr, epochs)
print("After {0} iterations b = {1}, k = {2}, error = {3}".format(epochs, b, k, compute_error(b, k, x_data, y_data)))

# ç”»å›¾
plt.plot(x_data, y_data, 'b.')
plt.plot(x_data, k*x_data + b, 'r')
plt.show()
```

##### è¿è¡Œç»“æœ

![](http://img.zhengyua.cn/img/20200303180056.png)

![](http://img.zhengyua.cn/img/20200303180118.png)

![](http://img.zhengyua.cn/img/20200303180147.png)

#### ä½¿ç”¨sklearnå®ç°-ä¸€å…ƒçº¿æ€§å›å½’

```python
from sklearn. linear_model import LinearRegression
import numpy as np
import matplotlib.pyplot as plt
#è½½å…¥æ•°æ®
data = np.genfromtxt("data.csv",delimiter=",")
x_data = data[:,0]
y_data = data[:,1]
plt.scatter(x_data,y_data)
plt.show()
print(x_data.shape)
#åŠ ä¸Šçº¬åº¦
x_data = data[:,0,np.newaxis]
y_data = data[:,1,np.newaxis]
print(x_data.shape)
print(y_data.shape)
#åˆ›å»ºå¹¶æ‹Ÿåˆæ¨¡å‹
model = LinearRegression()
model.fit(x_data, y_data)
#ç”»å›¾
plt.plot(x_data, y_data, 'b.')
plt.plot(x_data, model.predict(x_data), 'r')
plt.show()
```

##### è¿è¡Œç»“æœ

- ![](http://img.zhengyua.cn/img/20200303192540.png)



## åŸºäºæ¢¯åº¦ä¸‹é™æ³•çš„å¤šå…ƒçº¿æ€§å›å½’åº”ç”¨

### å¤šå…ƒçº¿æ€§å›å½’

- å•ç‰¹å¾

  ![](http://img.zhengyua.cn/img/20200303192828.png)

- å¤šç‰¹å¾

  ![](http://img.zhengyua.cn/img/20200303192849.png)

### å¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹

å½“Yå€¼çš„å½±å“å› ç´ ä¸æ˜¯å”¯ä¸€æ—¶ï¼Œé‡‡ç”¨å¤šå…ƒçº¿æ€§å›å½’

![](http://img.zhengyua.cn/img/20200303192924.png)

- ![](http://img.zhengyua.cn/img/20200303192941.png)
  - ![](http://img.zhengyua.cn/img/20200303193004.png)

### æ¢¯åº¦ä¸‹é™æ³•-å¤šå…ƒçº¿æ€§å›å½’

#### ä»£ç å®ç°

  ```python
import numpy as np
from numpy import genfromtxt
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
data = genfromtxt(r"Delivery.csv",delimiter=',')
print(data)
'''
[[100.    4.    9.3]
 [ 50.    3.    4.8]
 [100.    4.    8.9]
 [100.    2.    6.5]
 [ 50.    2.    4.2]
 [ 80.    2.    6.2]
 [ 75.    3.    7.4]
 [ 65.    4.    6. ]
 [ 90.    3.    7.6]
 [ 90.    2.    6.1]]
'''
#åˆ‡åˆ†æ•°æ®
x_data = data[:,:-1]
y_data = data[:,-1]
print(x_data)
print(y_data)
'''
[[100.   4.]
 [ 50.   3.]
 [100.   4.]
 [100.   2.]
 [ 50.   2.]
 [ 80.   2.]
 [ 75.   3.]
 [ 65.   4.]
 [ 90.   3.]
 [ 90.   2.]]
[9.3 4.8 8.9 6.5 4.2 6.2 7.4 6.  7.6 6.1]
'''
#å­¦ä¹ ç‡
lr = 0.0001
#å‚æ•°
theta0 = 0
theta1 = 0
theta2 = 0
#æœ€å¤§è¿­ä»£æ¬¡æ•°
epochs = 1000

#æœ€å°äºŒä¹˜æ³•
def compute_error(theta0, theta1, theta2, x_data, y_data):
    totalError = 0
    for i in range(0, len(x_data)):
        totalError += (y_data[i] - (theta1 * x_data[i,0] + theta2 * x_data[i,1] +theta0)) ** 2
    return totalError / float(len(x_data))

def gradient_descent_runner(x_data, y_data, theta0, theta1, theta2, lr, epochs):
    #è®¡ç®—æ€»æ•°æ®é‡
    m = float(len(x_data))
    
    for i in range(epochs):
        theta0_grad = 0
        theta1_grad = 0
        theta2_grad = 0
        #è®¡ç®—æ¢¯åº¦çš„æ€»å’Œå†æ±‚å¹³å‡
        for j in range(0, len(x_data)):
            theta0_grad += -(1/m) * (y_data[j] - (theta1 * x_data[j,0] + theta2 * x_data[j,1] + theta0))
            theta1_grad += -(1/m) * x_data[j,0] * (y_data[j] - (theta1 * x_data[j,0] + theta2 * x_data[j,1] + theta0))
            theta2_grad += -(1/m) * x_data[j,1] * (y_data[j] - (theta1 * x_data[j,0] + theta2 * x_data[j,1] + theta0)) 
        #æ›´æ–°
        theta0 = theta0 - (lr * theta0_grad)
        theta1 = theta1 - (lr * theta1_grad)
        theta2 = theta2 - (lr * theta2_grad)
    
    return theta0, theta1, theta2

print("Starting theta0 = {0}, theta1 = {1}, theta2 = {2}, error = {3}".
     format(theta0, theta1, theta2, compute_error(theta0, theta1, theta2, x_data, y_data)))
print("Running....")
theta0, theta1, theta2 = gradient_descent_runner(x_data, y_data, theta0, theta1, theta2, lr, epochs)
print("After {0} iterations theta0 = {1}, theta1 = {2}, theta2 = {3}, error = {4}".
     format(epochs, theta0, theta1, theta2, compute_error(theta0, theta1, theta2, x_data, y_data)))

'''
Starting theta0 = 0, theta1 = 0, theta2 = 0, error = 47.279999999999994
Running....
After 1000 iterations theta0 = 0.006971416196678632, theta1 = 0.08021042690771771, theta2 = 0.07611036240566814, error = 0.7731271432218118
'''

ax = plt.figure().add_subplot(111, projection = '3d')
ax.scatter(x_data[:,0], x_data[:,1], y_data, c = 'r', marker = 'o', s = 100)

x0 = x_data[:,0]
x1 = x_data[:,1]

#ç”Ÿæˆç½‘æ ¼çŸ©é˜µ
x0, x1 = np.meshgrid(x0, x1)
z = theta0 + x0 * theta1 + x1 * theta2
#ç”»3Då›¾
ax.plot_surface(x0, x1, z)
#è®¾ç½®åæ ‡è½´
ax.set_xlabel("Miles")
ax.set_ylabel('Num of Deleveries')
ax.set_zlabel('Time')

#æ˜¾ç¤º
plt.show()
  ```

#####  è¿è¡Œç»“æœ

![](http://img.zhengyua.cn/img/20200303200436.png)

#### åŸºäºsklearnå®ç°å¤šå…ƒçº¿æ€§å›å½’

```python
from sklearn import linear_model 
import numpy as np
from numpy import genfromtxt
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

data = genfromtxt(r"Delivery.csv",delimiter=',')
print(data)

#åˆ‡åˆ†æ•°æ®
x_data = data[:,:-1]
y_data = data[:,-1]

#åˆ›å»ºæ¨¡å‹
model = linear_model.LinearRegression()
model.fit(x_data,y_data)

#ç³»æ•°
print("coefficients:",model.coef_)

#æˆªè·
print("intercept:",model.intercept_)

#æµ‹è¯•
x_test = [[102,4]]
predict = model.predict(x_test)
print("predict:",predict)

ax = plt.figure().add_subplot(111, projection = '3d')
ax.scatter(x_data[:,0], x_data[:,1], y_data, c = 'r', marker = 'o', s = 100)

x0 = x_data[:,0]
x1 = x_data[:,1]

#ç”Ÿæˆç½‘æ ¼çŸ©é˜µ
x0, x1 = np.meshgrid(x0, x1)
z = model.intercept_ + x0 * model.coef_[0] + x1 * model.coef_[1]
#ç”»3Då›¾
ax.plot_surface(x0, x1, z)
#è®¾ç½®åæ ‡è½´
ax.set_xlabel("Miles")
ax.set_ylabel('Num of Deleveries')
ax.set_zlabel('Time')

#æ˜¾ç¤º
plt.show()
```

- è¿è¡Œç»“æœä¸ä¸Šé¢ç±»ä¼¼,å°±ä¸å±•ç¤ºå‡ºæ¥äº†

## å¤šé¡¹å¼å›å½’åŠåº”ç”¨

![](http://img.zhengyua.cn/img/20200305080528.png)

### ä»£ç å®ç°

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.lineaBr_model import LinearRegression

#è½½å…¥æ•°æ®
data = np.genfromtxt("job.csv",delimiter=",")
x_data = data[1:,1]
y_data = data[1:,2]
plt.scatter(x_data, y_data)
plt.show()

x_data = x_data[:,np.newaxis]
y_data = y_data[:,np.newaxis]
#åˆ›å»ºå¹¶æ‹Ÿåˆæ¨¡å‹
#è¿™é‡Œæ˜¯å¤šå…ƒçº¿æ€§å›å½’
model = LinearRegression()
model.fit(x_data, y_data)
#ç”»å›¾
plt.plot(x_data, y_data, 'b.')
plt.plot(x_data, model.predict(x_data), 'r')
plt.show()
```

![](http://img.zhengyua.cn/img/20200305082513.png)

- å¯ä»¥çœ‹å‡ºä½¿ç”¨å¤šå…ƒçº¿æ€§å›å½’,æ•ˆæœå¹¶ä¸æ˜¯å¤ªå¥½,æ‰€ä»¥æˆ‘ä»¬æ¢æˆå¤šé¡¹å¼å›å½’æ¥å¯¹æ•°æ®è¿›è¡Œç‰¹å¾å¤„ç†ä¸€ä¸‹

```python
#å®šä¹‰å¤šé¡¹å¼å›å½’,degree(åç½®å€¼)çš„å€¼å¯ä»¥è°ƒèŠ‚å¤šé¡¹å¼çš„ç‰¹å¾
poly_reg = PolynomialFeatures(degree = 5)
#ç‰¹å¾å¤„ç†
x_poly = poly_reg.fit_transform(x_data)
print(x_poly)
#å®šä¹‰å›å½’æ¨¡å‹
lin_reg = LinearRegression()
#è®­ç»ƒæ¨¡å‹
lin_reg.fit(x_poly, y_data)

#ç”»å›¾
plt.plot(x_data, y_data, 'b.')
plt.plot(x_data, lin_reg.predict(poly_reg.fit_transform(x_data)), c='r')
plt.title("Truth of Bluff (Polynomial Regression)")
plt.xlabel("Position level")
plt.ylabel("Salary")
plt.show()
```

![](http://img.zhengyua.cn/img/20200305082613.png)

- è¿™é‡Œçœ‹åˆ°é€šè¿‡è¿›è¡Œå¤šé¡¹å¼ç‰¹å¾å¤„ç†å,æ‹Ÿåˆç»“æœå°±æ¯”è¾ƒå¥½

## æ ‡å‡†æ–¹ç¨‹æ³•(Normal Equation)

![](http://img.zhengyua.cn/img/20200305082720.png)

- ![](http://img.zhengyua.cn/img/20200305082928.png)

**åˆ†å­å¸ƒå±€(Numerator-layout)**: åˆ†å­ä¸ºåˆ—å‘é‡æˆ–è€…åˆ†æ¯ä¸ºè¡Œå‘é‡

**åˆ†æ¯å¸ƒå±€(Denominator-layout)**:åˆ†å­ä¸ºè¡Œå‘é‡æˆ–è€…åˆ†æ¯ä¸ºåˆ—å‘é‡

> **æ±‚å¯¼å…¬å¼**:https://en.wikipedia.org/wiki/Matrix_calculus#Scalar-by-vector_identiti

![](http://img.zhengyua.cn/img/20200305083105.png)

![](http://img.zhengyua.cn/img/20200305083122.png)

![](http://img.zhengyua.cn/img/20200305083241.png)

### çŸ©é˜µä¸å¯é€†çš„æƒ…å†µ

- çº¿æ€§ç›¸å…³çš„ç‰¹å¾(å¤šé‡å…±çº¿æ€§)
- ç‰¹å¾æ•°æ®å¤ªå¤š(æ ·æœ¬æ•°m<=ç‰¹å¾æ•°é‡n)

### æ¢¯åº¦ä¸‹é™æ³•vsæ ‡å‡†æ–¹ç¨‹æ³•

![](http://img.zhengyua.cn/img/20200305083451.png)

### ä»£ç å®ç°

```python
import numpy as np
from numpy import genfromtxt
import matplotlib.pyplot as plt

#æ ‡å‡†æ–¹ç¨‹æ³•æ±‚è§£å›å½’å‚æ•°
def weights(xArr, yArr):
    xMat = np.mat(xArr)
    yMat = np.mat(yArr)
    xTx = xMat.T * xMat #çŸ©é˜µä¹˜æ³•
    #è®¡ç®—çŸ©é˜µçš„å€¼,å¦‚æœå€¼ä¸º0,è¯´æ˜è¯¥çŸ©é˜µæ²¡æœ‰é€†çŸ©é˜µ
    if np.linalg.det(xTx) == 0.0 :
        print("This matrix cannot do inverse")
        return
    #xTx.T ä¸º xTx çš„é€†çŸ©é˜µ
    ws = xTx.I * xMat.T * yMat
    return ws


#è½½å…¥æ•°æ®
data = np.genfromtxt("data.csv",delimiter=",")
x_data = data[:,0, np.newaxis]
y_data = data[:,1, np.newaxis]
plt.scatter(x_data, y_data)
plt.show()

#ç»™æ ·æœ¬æ·»åŠ åç½®é¡¹
X_data = np.concatenate((np.ones((100,1)), x_data), axis=1)
print(X_data.shape)

â€‹```
(100, 2)
â€‹```

ws = weights(X_data, y_data)
print(ws)

â€‹```
[[7.99102098]
 [1.32243102]]
â€‹```

#ç”»å›¾
x_test = np.array(([20],[80]))
y_test = ws[0] + x_test*ws[1]
y_data_predict = ws[0] + x_data*ws[1]
plt.plot(x_data, y_data, 'b.')
plt.plot(x_data, y_data_predict, 'r')
plt.show()
```

#### è¿è¡Œç»“æœ

![](http://img.zhengyua.cn/img/20200305085459.png)

## ç‰¹å¾ç¼©æ”¾äº¤å‰éªŒè¯æ³•

### ç‰¹å¾ç¼©æ”¾

**æ•°æ®å½’ä¸€åŒ–:**

æ•°æ®å½’ä¸€åŒ–å°±æ˜¯æŠŠæ•°æ®çš„å–å€¼èŒƒå›´å¤„ç†ä¸º0-1æˆ–è€…-1-1ä¹‹é—´ã€‚

- ä»»æ„æ•°æ®è½¬åŒ–ä¸º0-1ä¹‹é—´ï¼šnewValue = (oldValue-min)/(max-min)

  ä»»æ„æ•°æ®è½¬åŒ–ä¸º-1-1ä¹‹é—´ï¼šnewValue = ((oldValue-min)/(max-min)-0.5)*2

**å‡å€¼æ ‡å‡†åŒ–:**

xä¸ºç‰¹å¾æ•°æ®ï¼Œuä¸ºæ•°æ®çš„å¹³å‡å€¼ï¼Œsä¸ºæ•°æ®çš„æ–¹å·®

newValue = (oldValue-u)/s 

### äº¤å‰éªŒè¯æ³•

![](http://img.zhengyua.cn/img/20200305085823.png)

- é€šè¿‡åˆ‡åˆ†æ•°æ®,æ¯ä¸ªéƒ¨åˆ†åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†,ä¸”å°†æ¯ä¸ªéƒ¨åˆ†çš„è¯¯å·®åŠ èµ·æ¥è®¡ç®—å¹³å‡å€¼å³ä¸ºæœ€ç»ˆè¯¯å·®

## è¿‡æ‹Ÿåˆ(Overfitting)&æ­£åˆ™åŒ–(Regularized)

### è¿‡æ‹Ÿåˆ

**æ‹Ÿåˆæƒ…å†µ:**

- ![](http://img.zhengyua.cn/img/20200305090820.png)

  ![](http://img.zhengyua.cn/img/20200305090846.png)

**é˜²æ­¢è¿‡æ‹Ÿåˆ:**

- å‡å°‘ç‰¹å¾
- å¢åŠ æ•°æ®é‡
- æ­£åˆ™åŒ–

### æ­£åˆ™åŒ–

![](http://img.zhengyua.cn/img/20200305091000.png)

## å²­å›å½’/LASSOå›å½’/å¼¹æ€§ç½‘çš„åº”ç”¨

### å²­å›å½’(Ridge Regression)

>  w = (ğ‘‹^ğ‘‡ğ‘‹)^(âˆ’1)ğ‘‹^ğ‘‡y
>
> - å¦‚æœæ•°æ®çš„ç‰¹å¾æ¯”æ ·æœ¬ç‚¹è¿˜å¤šï¼Œæ•°æ®ç‰¹å¾nï¼Œæ ·æœ¬ä¸ªæ•°mï¼Œå¦‚æœn>mï¼Œåˆ™è®¡ç®—æ—¶ä¼šå‡ºé”™ã€‚å› ä¸º(ğ‘‹^ğ‘‡ğ‘‹)ä¸æ˜¯æ»¡ç§©çŸ©é˜µï¼Œæ‰€ä»¥ä¸å¯é€†ã€‚
>
> ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç»Ÿè®¡å­¦å®¶å¼•å…¥äº†å²­å›å½’çš„æ¦‚å¿µã€‚
>
> 

![](http://img.zhengyua.cn/img/20200305091404.png)

- ![](http://img.zhengyua.cn/img/20200305091429.png)

- å²­å›å½’æœ€æ—©æ˜¯ç”¨æ¥å¤„ç†ç‰¹å¾æ•°å¤šäºæ ·æœ¬çš„æƒ…å†µï¼Œç°åœ¨ä¹Ÿç”¨äºåœ¨ä¼°è®¡ä¸­åŠ å…¥åå·®ï¼Œä»è€Œå¾—åˆ°æ›´å¥½çš„ä¼°è®¡ã€‚åŒæ—¶ä¹Ÿå¯ä»¥è§£å†³å¤šé‡å…±çº¿æ€§çš„é—®é¢˜ã€‚**å²­å›å½’æ˜¯ä¸€ç§æœ‰åä¼°è®¡**ã€‚

![](http://img.zhengyua.cn/img/20200305091525.png)

**é€‰æ‹©ğœ†å€¼ï¼Œä½¿åˆ°ï¼š**

1. å„å›å½’ç³»æ•°çš„å²­ä¼°è®¡åŸºæœ¬ç¨³å®šã€‚
2. æ®‹å·®å¹³æ–¹å’Œå¢å¤§ä¸å¤ªå¤š

![](http://img.zhengyua.cn/img/20200305092001.png)

- ğœ†å€¼ä¸ºæ¨ªåæ ‡,æ‰€æ±‚å‚æ•°ä¸ºçºµåæ ‡

#### sklearn-ä»£ç å®ç°

> Longleyæ•°æ®é›†
>
> Longleyæ•°æ®é›†æ¥è‡ªJï¼Wï¼Longleyï¼ˆ1967ï¼‰å‘è¡¨åœ¨JASAä¸Šçš„ä¸€ç¯‡è®ºæ–‡ï¼Œæ˜¯å¼ºå…±çº¿æ€§çš„å®è§‚ç»æµæ•°æ®,åŒ…å«GNP deflator(GNPå¹³å‡æŒ‡æ•°)ã€GNP(å›½æ°‘ç”Ÿäº§æ€»å€¼)ã€Unemployed(å¤±ä¸šç‡)ã€ArmedForces(æ­¦è£…åŠ›é‡)ã€Population(äººå£)ã€year(å¹´ä»½)ï¼ŒEmlpoyed(å°±ä¸šç‡)ã€‚
>
> - LongLeyæ•°æ®é›†å› å­˜åœ¨ä¸¥é‡çš„å¤šé‡å…±çº¿æ€§é—®é¢˜ï¼Œåœ¨æ—©æœŸç»å¸¸ç”¨æ¥æ£€éªŒå„ç§ç®—æ³•æˆ–è®¡ç®—æœºçš„è®¡ç®—ç²¾åº¦

```python
import numpy as np
from numpy import genfromtxt
from sklearn import linear_model
import matplotlib.pyplot as plt

#è½½å…¥æ•°æ®
data = genfromtxt(r"longley.csv", delimiter=',')
print(data)

â€‹```
[[     nan      nan      nan      nan      nan      nan      nan      nan]
 [     nan   83.     234.289  235.6    159.     107.608 1947.      60.323]
 [     nan   88.5    259.426  232.5    145.6    108.632 1948.      61.122]
 [     nan   88.2    258.054  368.2    161.6    109.773 1949.      60.171]
 [     nan   89.5    284.599  335.1    165.     110.929 1950.      61.187]
 [     nan   96.2    328.975  209.9    309.9    112.075 1951.      63.221]
 [     nan   98.1    346.999  193.2    359.4    113.27  1952.      63.639]
 [     nan   99.     365.385  187.     354.7    115.094 1953.      64.989]
 [     nan  100.     363.112  357.8    335.     116.219 1954.      63.761]
 [     nan  101.2    397.469  290.4    304.8    117.388 1955.      66.019]
 [     nan  104.6    419.18   282.2    285.7    118.734 1956.      67.857]
 [     nan  108.4    442.769  293.6    279.8    120.445 1957.      68.169]
 [     nan  110.8    444.546  468.1    263.7    121.95  1958.      66.513]
 [     nan  112.6    482.704  381.3    255.2    123.366 1959.      68.655]
 [     nan  114.2    502.601  393.1    251.4    125.368 1960.      69.564]
 [     nan  115.7    518.173  480.6    257.2    127.852 1961.      69.331]
 [     nan  116.9    554.894  400.7    282.7    130.081 1962.      70.551]]
â€‹```

#åˆ‡åˆ†æ•°æ®
x_data = data[1:,2:]
y_data = data[1:,1]

#åˆ›å»ºæ¨¡å‹
#ç”Ÿæˆ50ä¸ªå€¼
alphas_to_test = np.linspace(0.001, 1)
#åˆ›å»ºæ¨¡å‹,ä¿å­˜è¯¯å·®å€¼,CV:äº¤å‰éªŒè¯
model = linear_model.RidgeCV(alphas = alphas_to_test, store_cv_values= True)
model.fit(x_data, y_data)

#å²­ç³»æ•°
print(model.alpha_)
#losså€¼
print(model.cv_values_.shape)

â€‹```
0.40875510204081633
(16, 50)
â€‹```

#ç”»å›¾
#å²­ç³»æ•°è·ŸLosså€¼çš„å…³ç³»
plt.plot(alphas_to_test, model.cv_values_.mean(axis=0))
#é€‰å–çš„å²­ç³»æ•°çš„ä½ç½®
plt.plot(model.alpha_, min(model.cv_values_.mean(axis=0)), 'ro')
plt.show()

#ç®€å•æµ‹è¯•
model.predict(x_data[2,np.newaxis])
y_data[2]
â€‹```
out:array([88.11216213])
out:88.2
â€‹```
```



##### è¿è¡Œç»“æœ

![](http://img.zhengyua.cn/img/20200305094231.png)



#### æ ‡å‡†æ–¹ç¨‹æ³•-ä»£ç å®ç°

```python
import numpy as np
from numpy import genfromtxt
from sklearn import linear_model
import matplotlib.pyplot as plt

#è½½å…¥æ•°æ®
data = genfromtxt(r"longley.csv", delimiter=',')
print(data)
#åˆ‡åˆ†æ•°æ®
x_data = data[1:,2:]
y_data = data[1:,1,np.newaxis]
print(x_data.shape)
print(y_data.shape)

â€‹```
[[     nan      nan      nan      nan      nan      nan      nan      nan]
 [     nan   83.     234.289  235.6    159.     107.608 1947.      60.323]
 [     nan   88.5    259.426  232.5    145.6    108.632 1948.      61.122]
 [     nan   88.2    258.054  368.2    161.6    109.773 1949.      60.171]
 [     nan   89.5    284.599  335.1    165.     110.929 1950.      61.187]
 [     nan   96.2    328.975  209.9    309.9    112.075 1951.      63.221]
 [     nan   98.1    346.999  193.2    359.4    113.27  1952.      63.639]
 [     nan   99.     365.385  187.     354.7    115.094 1953.      64.989]
 [     nan  100.     363.112  357.8    335.     116.219 1954.      63.761]
 [     nan  101.2    397.469  290.4    304.8    117.388 1955.      66.019]
 [     nan  104.6    419.18   282.2    285.7    118.734 1956.      67.857]
 [     nan  108.4    442.769  293.6    279.8    120.445 1957.      68.169]
 [     nan  110.8    444.546  468.1    263.7    121.95  1958.      66.513]
 [     nan  112.6    482.704  381.3    255.2    123.366 1959.      68.655]
 [     nan  114.2    502.601  393.1    251.4    125.368 1960.      69.564]
 [     nan  115.7    518.173  480.6    257.2    127.852 1961.      69.331]
 [     nan  116.9    554.894  400.7    282.7    130.081 1962.      70.551]]
(16, 6)
(16, 1)
â€‹```

print(np.mat(x_data).shape)
print(np.mat(y_data).shape)
#ç»™æ ·æœ¬é¡¹åŠ åç½®å€¼
X_data = np.concatenate((np.ones((16,1)), x_data),axis=1)
print(X_data.shape)

â€‹```
(16, 6)
(16, 1)
(16, 7)
â€‹```

#å²­å›å½’æ ‡å‡†æ–¹ç¨‹æ³•æ±‚è§£å›å½’å‚æ•°
def weights(xArr, yArr, lam=0.2):
    xMat = np.mat(xArr)
    yMat = np.mat(yArr)
    xTx = xMat.T * xMat #çŸ©é˜µä¹˜æ³•
    rxTx = xTx + np.eye(xMat.shape[1]) * lam
    if np.linalg.det(rxTx) == 0.0:
        print("This mattrix cannot do inverse")
        return
    ws = rxTx.I * xMat.T * yMat
    return ws

ws = weights(X_data, y_data)
print(ws)

â€‹```
[[ 7.38107882e-04]
 [ 2.07703836e-01]
 [ 2.10076376e-02]
 [ 5.05385441e-03]
 [-1.59173066e+00]
 [ 1.10442920e-01]
 [-2.42280461e-01]]
â€‹```

#è®¡ç®—é¢„æµ‹å€¼
print(np.mat(X_data) * np.mat(ws))

â€‹```
[[ 83.55075226]
 [ 86.92588689]
 [ 88.09720228]
 [ 90.95677622]
 [ 96.06951002]
 [ 97.81955375]
 [ 98.36444357]
 [ 99.99814266]
 [103.26832266]
 [105.03165135]
 [107.45224671]
 [109.52190685]
 [112.91863666]
 [113.98357055]
 [115.29845063]
 [117.64279933]]
â€‹```
```



### LASSO

> - Tibshirani(1996)æå‡ºäº†Lasso(The Least Absolute Shrinkage and 
>   Selectionator operator)ç®—æ³•
> - é€šè¿‡æ„é€ **ä¸€ä¸ªä¸€é˜¶æƒ©ç½šå‡½æ•°è·å¾—ä¸€ä¸ªç²¾ç‚¼çš„æ¨¡å‹**ï¼›é€šè¿‡æœ€ç»ˆç¡®å®šä¸€äº›
>   æŒ‡æ ‡ï¼ˆå˜é‡ï¼‰çš„ç³»æ•°ä¸ºé›¶ï¼ˆå²­å›å½’ä¼°è®¡ç³»æ•°ç­‰äº0çš„æœºä¼šå¾®ä¹å…¶å¾®ï¼Œ
>   é€ æˆç­›é€‰å˜é‡å›°éš¾ï¼‰ï¼Œè§£é‡ŠåŠ›å¾ˆå¼ºã€‚
> - æ“…é•¿å¤„ç†å…·æœ‰å¤šé‡å…±çº¿æ€§çš„æ•°æ®ï¼Œä¸å²­å›å½’ä¸€æ ·æ˜¯**æœ‰åä¼°è®¡** ã€‚

#### LASSOä¸å²­å›å½’

![](http://img.zhengyua.cn/img/20200306111653.png)

- å›¾åƒæ¯”è¾ƒ

  ![](http://img.zhengyua.cn/img/20200306111842.png)

- ![](http://img.zhengyua.cn/img/20200306112924.png)

#### sklearn-ä»£ç å®ç°Lasso

```python
import numpy as np
from numpy import genfromtxt
from sklearn import linear_model

#è½½å…¥æ•°æ®
data = genfromtxt(r"longley.csv",delimiter = ',')
print(data.shape)
#åˆ‡åˆ†æ•°æ®
x_data = data[1:,2:]
y_data = data[1:,1]
print(x_data.shape)
print(y_data.shape)
â€‹```
(17, 8)
(16, 6)
(16,)
â€‹```

#åˆ›å»ºæ¨¡å‹,å¾—åˆ°ä¸€ä¸ªåˆé€‚çš„è¯¯å·®å€¼,ç”±äºäº¤å‰éªŒè¯å…¶å‡½æ•°å†…éƒ¨è‡ªåŠ¨ç”Ÿæˆéšæœºæ•°è¿›è¡Œæµ‹è¯•
model = linear_model.LassoCV()
model.fit(x_data, y_data)
#lassoç³»æ•°
print(model.alpha_)
#ç›¸å…³ç³»æ•°
print(model.coef_)
#å…¶ä¸­ä¸‰ä¸ªç‰¹å¾æœ‰å…±çº¿æ€§å³ä¸º0

â€‹```
20.03464209711722
[0.10206856 0.00409161 0.00354815 0.         0.         0.        ]
â€‹```

#é¢„æµ‹å€¼
print(model.predict(x_data[-2,np.newaxis]))
#çœŸå®å€¼
print(y_data[-2])

â€‹```
[115.6461414]
115.7
â€‹```
```

### å¼¹æ€§ç½‘(Elastic Net)

>  ![](http://img.zhengyua.cn/img/20200306114817.png)
>
> å¾ˆå®¹æ˜“çœ‹å‡º,q=2æ—¶å°±æ˜¯ä¸ºå²­å›å½’,q=1ä¸ºLassoå›å½’

![](http://img.zhengyua.cn/img/20200306114933.png)

#### sklearn-ä»£ç å®ç°ElasticNet

ç”±äºéƒ¨åˆ†ç»“æœä¸ä¸Šé¢ç±»ä¼¼,è¿™é‡Œå°±ä¸è´´å‡ºæ¥äº†

```PYTHON
import numpy as np
from numpy import genfromtxt
from sklearn import linear_model

#è½½å…¥æ•°æ®
data = genfromtxt(r"longley.csv", delimiter=',')
print(data)
print(data.shape)

#åˆ‡åˆ†æ•°æ®
x_data = data[1:,2:]
y_data = data[1:,1]

#åˆ›å»ºæ¨¡å‹
model = linear_model.ElasticNetCV()
model.fit(x_data, y_data)

#lå¼¹æ€§ç½‘ç³»æ•°
print(model.alpha_)
#ç›¸å…³ç³»æ•°
print(model.coef_)

â€‹```
42.96498005089394
[0.1016487  0.00416716 0.00349843 0.         0.         0.        ]
â€‹```

#é¢„æµ‹å€¼
print(model.predict(x_data[-2,np.newaxis]))
#çœŸå®å€¼
print(y_data[-2])

â€‹```
[115.6037171]
115.7
â€‹```
```

